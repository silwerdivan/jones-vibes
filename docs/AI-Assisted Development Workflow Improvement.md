Here is the text converted to Markdown format:

# Structured Vibe Coding 2.0: Architecting Production-Grade LLM Workflows for Brownfield Refactoring with Gemini CLI (Q4 2025 Edition)

## Part I: The Architecture of Reliable Vibe Coding

The initial implementation of Structured Vibe Coding (SVC) successfully provided a framework for rapid greenfield Minimum Viable Product (MVP) creation, utilizing the core sequence of Specification, Blueprint, and To-Do list. However, transitioning this methodology to a stable, production-ready environment, especially when dealing with complex brownfield tasks like visual refactoring, demands rigorous architectural updates. The key challenges encountered—context drift, manual workflow friction, and brownfield context collapse—require moving beyond simple prompt engineering toward robust agent execution and advanced context management.

### 1.1 Refining the SVC Pipeline for Production Readiness

The foundational strength of SVC lies in its document-driven approach, which translates high-level project goals into executable, atomic units. In a brownfield context, these documents take on specialized roles. The initial **Specification** defines what the visual upgrade must achieve, listing new measurable targets such as specific color schemes, typography rules, and component states. The **Blueprint** translates this specification into how the architectural steps will be executed, detailing component restructuring and file modification order. The **To-Do List** serves as the agent’s execution roadmap. For brownfield refactoring, this roadmap must be refined to explicitly manage dependencies and context calls, ensuring each step is small enough to be completed deterministically without overwhelming the Large Language Model (LLM).

#### Test-Driven Refactoring (TDR)

For refactoring tasks, especially those related to subjective visual changes, the traditional Test-Driven Development (TDD) cycle must be adapted into **Test-Driven Refactoring (TDR)**. TDD is fundamentally a rhythmic loop of Red, Green, Refactor. The TDR adaptation involves writing tests for the intended new structure or style before the code exists. For a visual upgrade, this means asserting that a component now uses a specific CSS class, adheres to a new naming convention, or that the Document Object Model (DOM) structure has been successfully reorganized.

While traditional TDD focuses on functional correctness—ensuring a function returns the correct value—TDR for visual upgrades must shift its focus to **structural correctness and visual contract enforcement**. The **Red phase** is no longer merely a failed function call, but a failed assertion that a critical structural or styling element, such as a new CSS variable or a required structural element, is present. This methodical approach forces the LLM to address both style implementation and underlying structure simultaneously, translating the subjective goal of "looks visually attractive" into an objective, pass/fail standard that the AI agent can execute.

### 1.2 Eliminating Context Drift: Precision Task Control

The user's experience—the LLM continuing to the next to-do item unprompted—is a direct symptom of relying on the LLM's default, highly generative behavior. This over-generation is particularly problematic in automated workflows because it violates the atomic nature of the To-Do list, risking incomplete commits and unverified code changes. Furthermore, managing long, interactive sessions in the terminal is inherently unstable; system timeouts or unexpected errors can occur when the agent is waiting for user confirmation to apply large changes, resulting in session crashes and lost progress. Reliable SVC 2.0 workflows must solve for this determinism.

#### Enforcement via System Instructions (The Non-Negotiable Contract)

The initial defense against context drift is a rigorously enforced **system prompt**. This prompt establishes a strict constraint, enforcing single-output execution on the LLM. The system prompt must contain unambiguous instructions, such as: "You are restricted to completing only the currently defined To-Do item. Output ONLY the necessary code blocks for this task. Do NOT provide commentary, transition to the next task, or offer the next step." This language transforms the LLM from a conversational partner into a deterministic code executor.

#### Implementing Deterministic Output via API Settings

Beyond the system prompt, technical configurations within the LLM API settings are essential for enforcing task boundaries. The most effective technical solution is configuring explicit **Stop Sequences**. A stop sequence is a string that, when generated by the model, immediately halts further token generation. By configuring the Gemini CLI or API to recognize custom sequences (e.g., `\n--- END OF TASK ---` or recognizing the pattern of the next item, such as `\n## TODO 2:`), generation is prevented from rolling over into the next task, ensuring strict adherence to the active To-Do item.

Furthermore, for reliable code generation, tuning the model’s **sampling parameters** is crucial. **Low Temperature settings** (typically 0.1 to 0.3) ensure the model selects the highest probable next token, encouraging deterministic, factual, and concise output necessary for TDD adherence. Similarly, using a **low Top P value** focuses the model on the most confident tokens, reducing creative deviation from the strict Blueprint requirements. This deterministic approach, implemented through the necessary configurations, dictates that the LLM's role be strictly non-interactive code generation. Relying on interactive confirmation is a bottleneck and a significant risk factor due to potential session timeouts. Reliable SVC 2.0 demands that confirmation, commit, and context refresh are delegated to automated tools and the session loop, bypassing the necessity for human intervention mid-generation.

#### LLM Generation Control Parameters (Gemini CLI Configuration)

| Parameter/Mechanism | Recommended Setting for SVC 2.0 | Purpose in Context Engineering |
| :--- | :--- | :--- |
| Stop Sequences | `\n--- END OF TASK ---`, `\n## TODO [0-9]:` (Regex) | Prevents model from rolling over to the next item, enforcing single-task completion. |
| Temperature (Sampling) | Low (e.g., 0.1 to 0.3) | Encourages deterministic, factual, and concise code generation required for TDD adherence. |
| System Instructions | Rigorous, non-negotiable enforcement of single code block output and strict silence until the next human prompt. | |
| Max Length | Configured based on task complexity (e.g., 2048 tokens) | Guards against runaway generation and excessive token consumption and token cost. |

### 1.3 Integrating the DevOps Loop: Automated Version Control

The requirement to manually execute `git commit` and `push` commands after every LLM-generated change introduces unnecessary friction and slows down the "vibe coding" flow. Automation of version control is non-negotiable for enterprise-level projects.

#### Local Automation via `run_shell_command`

The Gemini CLI provides the `run_shell_command` tool, which allows the LLM agent to interact directly with the underlying operating system. By enabling `tools.shell.enableInteractiveShell: true` in the Gemini CLI configuration, the LLM can be prompted to execute local Git operations. For example, the agent can run: `run_shell_command('git add. && git commit -m "feat: completed todo [X] refactor"')`. This capability immediately resolves the manual commit pain point.

However, the most strategic and reliable use of `run_shell_command` is not for commit/push operations, which can sometimes be unreliable or require interactive confirmation, but for **running the unit tests**. Executing `npm test` or equivalent commands post-generation allows the LLM to verify the "**Green**" phase of the TDD loop immediately, providing objective feedback on correctness.

#### Decoupling Workflows with GitHub Actions

While local shell automation is useful, the gold standard for robust, high-integrity projects is delegating the version control workflow to a Continuous Integration/Continuous Deployment (CI/CD) pipeline. The Gemini CLI supports this delegation via the `gemini setup github` command, which integrates the agent’s workflow with GitHub Actions.

This decoupling separates concerns: the LLM generates the code locally, and the user reviews and confirms the change. Once the user pushes the generated code (not the LLM’s command), the GitHub Action pipeline is triggered. This pipeline, configured using the Gemini CLI setup, handles tasks such as code triage, pull request review, and final commit integrity, enforcing **prompt versioning** and stable rollbacks. Managing prompt versions—tracking templates in Git alongside the code—ensures reproducibility and accountability across iterations, a crucial feature for any production environment.

## Part II: Advanced Context Management for Brownfield Projects

The user's most significant bottleneck was the LLM’s struggle to handle the visual upgrade, which required adapting existing HTML, CSS, and JavaScript. This brownfield challenge is a fundamental architectural problem that cannot be solved with better prompting alone. Refactoring a visual guide requires simultaneous, deep context across all associated files (DOM structure, styling rules, interactive logic), often exceeding the limits of the LLM’s raw context window.

### 2.1 The Context Challenge in Visual Refactoring

Brownfield projects, particularly those involving multi-file refactoring like visual upgrades, demand that the LLM agent possess dynamic awareness of the existing codebase. The LLM needs the ability to answer precise, stateful queries: "What is the current value of the `main-game-canvas` class in `style.css`?" or "Where is the `game-loop` function defined in `logic.js`?" When the codebase is large (thousands of lines of HTML, CSS, and JS), providing this entire corpus within a single prompt becomes impossible due to token limits, leading to what is termed **"context collapse."** The LLM loses track of what exists before attempting to modify it, resulting in destructive or inconsistent changes.

This architectural limitation necessitates an external solution that can provide context dynamically, on demand, which is precisely the function of the **Model Context Protocol (MCP)**.

### 2.2 Gemini CLI and FastMCP Integration (SVC 2.0’s Core Enabler)

The Model Context Protocol (MCP) provides the necessary architecture for external systems (**MCP Servers**) to supply context, tools, and data capabilities to the LLM agent (the **MCP Host**). This architecture bypasses the inherent limitations of the prompt's context window by allowing the LLM to actively query the external state of the project.

#### The FastMCP Solution (Q4 2025 Standard)

As of September 2025, the Gemini CLI has been engineered to integrate seamlessly with **FastMCP**, a leading Python library for building MCP servers. This integration is the technical backbone for reliable, scalable brownfield development in SVC 2.0.

The integration simplifies the process of making custom MCP tools and prompts instantly available within the Gemini CLI environment using the command `fastmcp install gemini-cli server.py`. This integration fundamentally transforms the Gemini CLI from a conversational code generator into a **full-fledged AI Agent Executor Environment**. The LLM is no longer passively guessing the context based on truncated input; it is actively querying the authoritative state of the project through defined, structured tools.

#### Architectural Roles in Brownfield Context

The successful implementation of brownfield refactoring depends on distributing roles between the Gemini CLI and the custom FastMCP server, allowing controlled access to the codebase.

*   **MCP Server (FastMCP):** Built using Python, the server acts as the authoritative source for the codebase, indexing the HTML, CSS, and JS files.
*   **Resource Providers:** These are custom FastMCP components designed to allow the LLM to read files on demand. For instance, the LLM can call `ctx.read_resource("resource://html/game.html")`. This capability is critical for brownfield work, as it loads the necessary context dynamically via MCP without counting against the static prompt window, directly solving the context collapse issue.
*   **Custom Tools:** FastMCP allows defining custom Python functions that map to slash commands within the Gemini CLI (e.g., `/get_style_rules.scoreboard`). These tools allow the LLM to perform complex analysis, such as dependency checking or controlled modification, which goes far beyond simple text generation.

The ability of the LLM to decide when and how to access external context ensures that changes are additive or corrective, rather than destructive. Before the LLM rewrites a section of CSS, it executes a tool to confirm the existing rules and their dependencies, ensuring the refactoring is safe and contextually sound.

#### Architectural Requirements for Brownfield Code Context via MCP/FastMCP

| Component | Function in Visual Upgrade | Gemini CLI Tool Integration |
| :--- | :--- | :--- |
| MCP Host (Gemini CLI) | The core AI application that executes instructions and communicates with the external server. | Launches the agent and facilitates command execution. |
| MCP Server (FastMCP) | External service hosting project context and custom tools. Built using Python and instantiated with `FastMCP("My Refactoring Server")`. | Installed using `fastmcp install gemini-cli server.py`. |
| Resource Providers | Specific endpoints defined in the FastMCP server that enable the LLM to read existing files (HTML, CSS, JS) on demand. | Allows dynamic context access, resolving the context window limitation. |
| Custom Refactoring Tools | Defined Python functions (e.g., `/refactor_css_rule`, `/check_dom_attribute`) used to perform complex, multi-file analysis and controlled modifications. | Mapped as slash commands within the Gemini CLI prompt environment. |

## Part III: The Visual Upgrade Blueprint: Decomposition and TDD

The user’s initial failure to achieve a successful visual upgrade stemmed from attempting the process in "one go," which led to the context collapse described previously. The successful methodology must enforce architectural decomposition, ensuring the refactoring is broken down into units small enough for deterministic execution.

### 3.1 Translating Aesthetics to Objective Requirements

Subjective visual goals, such as achieving a "modern look," must be translated into measurable, objective requirements within the **Specification** document. This high-fidelity specification must explicitly define the new color variables, typography stack, layout grid rules, and responsive breakpoints.

#### Structuring the Brownfield Blueprint

The **Blueprint** must break this refactoring goal into isolated, atomic components that align with the TDR approach. The size of the task directly correlates with the context required; therefore, decomposition must minimize the required context for each step while relying on the MCP server to provide the global, searchable context for all steps.

For example, instead of a single task, the Blueprint must include sequenced, isolated tasks:
*   Define new CSS variables in `theme.css`.
*   Refactor the `scoreboard.html` DOM structure to use the new layout class.
*   Write structural test assertions for the refactored scoreboard.
*   Generate `scoreboard.css` (Green phase).
*   Refactor the adjacent primary game loop component.

Since visual goals are inherently iterative and subject to human review, **prompt versioning** is essential. The specific prompt template used to generate the Blueprint from the Spec should be versioned (e.g., `blueprint_v1.2_visual_upgrade_1.md`). If an iteration fails, the prompt template is rolled back and institutionalized with lessons learned, ensuring consistency across development cycles.

### 3.2 TDD for Visual Refactoring: The "Structurally Green" Loop

The standard TDD loop must be formally extended to include a post-refactor human review step and must leverage the advanced context capabilities of the MCP environment. This refined workflow, **Test-Driven Refactoring (TDR)**, provides the rigor needed for multi-file style and structure changes.

#### Defining the TDD Loop for Style Changes

1.  **Red Phase (Test Fail):** The user or LLM writes a test assertion (using a framework like Vitest) confirming the desired new state. This might assert that the component now contains a specific structure (e.g., a new `div` with a `data-widget-v2` attribute) or that the compiled CSS property reflects the required style (e.g., `color: var(--primary-color)`). The test is run and fails, establishing the objective goalpost.
2.  **Green Phase (Code Generation):** The LLM uses the MCP **Resource Providers** to dynamically load the existing HTML/CSS context, ensuring it understands the current state. It then generates the minimal required code to make the test pass (e.g., changing a class name or adding a single CSS rule).
3.  **Refactor Phase (Cleanup):** Once the structural test is passing, the LLM, leveraging its persistent, indexed project context via FastMCP tools, cleans up old, unused styles or consolidates CSS properties across files. For instance, the LLM might execute a custom tool `/analyze_css_dependencies` to ensure refactoring a single class does not cause unintended side effects across the application. This contextual awareness is paramount for safe brownfield refactoring.
4.  **Confirm Phase (Verification):** This phase incorporates the **Human-in-the-Loop** oversight. After achieving "structurally green" via the unit tests, the human performs a visual review. The LLM then executes the final internal verification step, using `run_shell_command('npm test')` to ensure all tests remain green, immediately followed by the automated commitment of the verified change.

The incorporation of MCP tools within the TDR cycle is the critical distinction for SVC 2.0. The LLM can run `/get_dom_tree game.html` to confirm the injection point before attempting to change the HTML, or run `/analyze_css_dependencies` during the Refactor step. This active context inquiry allows the agent to safely navigate the complexities of a multi-file brownfield project.

#### The Four-Phase TDD Cycle for Visual Refactoring

| Phase | Goal | LLM Action / Gemini CLI Tooling | Context Mechanism |
| :--- | :--- | :--- | :--- |
| **RED (Test Fail)** | Define the structural/visual change required (e.g., H1 must have class `hero-title`). | User creates the failing unit test asserting the new structure/style. | Blueprint defines the target. |
| **GREEN (Code Generation)** | Write the minimum HTML/CSS/JS code to make the test pass. | LLM uses **Resource Providers** to read current files and generate only the necessary additions or modifications. | Dynamic context loading via FastMCP. |
| **REFACTOR (Cleanup)** | Apply best practices, remove legacy/redundant styling, and improve code elegance without breaking tests. | LLM uses **Custom Tools** (e.g., `/analyze_css_dependencies`) to confirm safety and execute cleanup across files. | Persistent, indexed project context via MCP. |
| **CONFIRM (Verification)** | Human visual check and automation of version control persistence. | LLM executes `run_shell_command('npm test')` to ensure all tests remain green, followed by automated Git commit. | Local shell environment access. |

## Part IV: Prescriptive Implementation and Future Workflows

### 4.1 The 7-Step Structured Vibe Coding 2.0 Refactoring Workflow

The following prescriptive workflow integrates all the discussed architectural and methodological improvements, ensuring reliable, deterministic refactoring for the creation of a visually attractive MVP.

1.  **Preparation (Blueprint & FastMCP):** Confirm that the Visual Upgrade Specification has been meticulously translated into an atomic Blueprint and a sequential To-Do list. Crucially, the **FastMCP server must be installed** (`pip install fastmcp>=2.12.3`) **and configured** (`fastmcp install gemini-cli server.py`) to run concurrently, indexed to the HTML/CSS/JS project codebase.
2.  **Task Selection and Context Enforcement:** Launch the Gemini CLI session. Load the session with the rigorous system prompt (enforcing single output) and apply the deterministic API parameters (Stop Sequences and Low Temperature). Select To-Do item #1.
3.  **Red Phase (Test Writing):** Prompt the LLM agent to analyze the Blueprint and utilize its tools to write the specific TDR test case for the selected To-Do item (e.g., `run_shell_command('npm run write-test -- componentX')`). The LLM confirms the test fails.
4.  **Green Phase (Code Generation):** Prompt the LLM to implement the change required by the Red test. The agent will internally use its configured tools—specifically **FastMCP Resource Providers**—to check the existing code context before generating the necessary additions or modifications. The LLM outputs the modified code blocks, and the **Stop Sequence** immediately halts further generation.
5.  **Test Verification:** The LLM executes the shell command to run the test suite (`run_shell_command('npm test')`). If tests fail, the LLM is prompted to analyze the failure and return to the Green phase.
6.  **Refactor and Clean-up:** Once the test suite is green, the LLM is prompted to use **custom MCP tools** (e.g., `/refactor_css_rule`) to clean up legacy code and ensure code elegance without breaking the established tests.
7.  **Commit and Next Task:** The human performs a final visual review (**Human-in-the-Loop** oversight). The human accepts the changes and commits the files locally. Pushing the changes triggers the **GitHub Action CI/CD pipeline**, which ensures prompt versioning and stable deployment. The process then iterates to To-Do item #2.

### 4.2 Reference Implementation Snippets

#### Example System Prompt Template (Enforcing Determinism)

The system instruction should be placed at the highest context level and be non-negotiable:

> "You are an expert HTML/CSS/JS refactoring agent. Your goal is to complete the single, active To-Do item provided by the user. You have access to project context via FastMCP tools. Your response **MUST contain ONLY the necessary code blocks and MUST NOT include any conversational commentary, explanations, or transition to the next task**. After outputting the code, you **MUST use the string `--- END OF TASK ---` as a stop sequence**, followed by an immediate session wait, pending user review."

#### Gemini CLI settings.json Configuration

The following configuration demonstrates how to enable the necessary shell tool for test execution and tune the LLM parameters for deterministic code generation.

```json
{
  "model": {
    "temperature": 0.1,
    "max_output_tokens": 2048,
    "stop_sequences":
  },
  "tools": {
    "shell": {
      "enabled": true,
      "enableInteractiveShell": true,
      "description": "Execute local shell commands, primarily for running tests (npm test) or executing git commits."
    }
  }
}
```

### 4.3 Future-Proofing and Scaling SVC 2.0

The successful implementation of Structured Vibe Coding 2.0 hinges on a crucial transformation: the practitioner must shift their focus from being a **prompt engineer**—constantly tweaking prompts to solve context issues—to becoming an **Agent Architect**. This role involves building and maintaining sophisticated, tool-rich, context-aware execution environments, namely the **MCP servers**.

The MCP foundation built with FastMCP enables future **scaling to multi-agent workflows**. For instance, a complex visual refactoring could involve one LLM agent dedicated solely to updating the HTML/DOM structure, another agent specializing in CSS optimization and BEM methodology enforcement, and a third agent handling corresponding JavaScript refactoring. These separate, specialized agents would all synchronize their actions and access the unified, current state of the code through the central FastMCP server.

By institutionalizing **prompt versioning**, enforcing deterministic output via configuration, and leveraging the dynamic context management provided by Gemini CLI’s integration with **FastMCP**, the process moves from a fragile, conversational coding method to a robust, enterprise-grade architecture capable of reliably handling complex brownfield projects, such as iterative and visually sensitive game MVP development. This approach ensures that the final game MVP is not only functional but also structurally clean and visually attractive, ready for production deployment.